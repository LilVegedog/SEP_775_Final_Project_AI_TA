{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f506abe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openai -U\n",
    "# !pip install llama-index llama-index-core llama-index-readers-file llama-index-llms-ollama llama-index-llms-huggingface llama-index-embeddings-huggingface llama-index-llms-openai llama-index-embeddings-openai -U\n",
    "# !pip install spacy -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15994c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import answer_relevancy, faithfulness, context_relevancy, answer_similarity\n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import Settings, VectorStoreIndex, SimpleDirectoryReader, \\\n",
    "    ServiceContext, StorageContext, load_index_from_storage, get_response_synthesizer, \\\n",
    "    PromptTemplate\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor, MetadataReplacementPostProcessor\n",
    "from llama_index.core.node_parser import  SentenceSplitter, SentenceWindowNodeParser\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "#os.environ['HUGGINGFACE_API_KEY']=os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "#os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "814ca01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_NAME = \"gpt-3.5-turbo\"                              # LLM model path from OpenAI\n",
    "TOKENIZER_NAME = \"gpt-3.5-turbo\"                        # Tokenizer path from OpenAI\n",
    "INPUT_DATA_PATH = '../data/txt_from_pdf_with_file_name' # Path to the input data\n",
    "QUESTION_ANS_PATH = '../data/question_answer_short.json'       # Path to the question list\n",
    "QCR_EVAL_SAVE_PATH = \"../RAG_eval_results/QCR_eval_results.csv\" # Path to save question-context-response evaluation results \n",
    "# Path to save average question-context-response evaluation results for different hyperparameters choices\n",
    "HYPER_PARAM_EVAL_SAVE_PATH = \"../RAG_eval_results/HYPER_PARAM_eval_results.csv\" \n",
    "\n",
    "cand_EMBED_MODEL = [\"text-embedding-3-small\",\"BAAI/bge-small-en-v1.5\"]   # model path for candidate embedding models\n",
    "\n",
    "# candidate chunk size, chunk overlap, and similarity top-k combinations\n",
    "cand_CHUNK_SIM_TOP_K = [{'chunk_size':512, 'chunk_overlap':20, 'sim_top_k':2},\n",
    "                        {'chunk_size':256, 'chunk_overlap':10, 'sim_top_k':4},\n",
    "                        {'chunk_size':128, 'chunk_overlap':10, 'sim_top_k':8}] \n",
    "# candidate system prompts \n",
    "cand_SYS_PROMPT=[\"\"\"\n",
    "You are an AI teaching Assistant for the SEP 775 course. \n",
    "You will provide an interactive platform for students to ask questions and receive guidance on course materials.\n",
    "Your goal is to answer questions as accurately as possible based on the instructions and context provided.\n",
    "If you found the answer based on the context provided, you should provide the answer first, then at the end, beginning a new sentence with the words \"Source:\", followed by the name of the lecture, or assignment, or paper if possible.\n",
    "\"\"\",\n",
    "                \"\"\"\n",
    "You are an AI Teaching Assistant for the SEP 775 course. \n",
    "Your job is to answer students' questions about course materials according to the instructions and context provided.\n",
    "If you found the answer based on the context provided, you should provide the answer first, then at the end, beginning a new sentence with the words \"Source:\", followed by the name of the lecture, or assignment, or paper if possible.\n",
    "\"\"\"]     \n",
    "\n",
    "# Customized prompt for query engine\n",
    "QA_PROMPT_TPL_str = (\n",
    "    \"Below is the context information related to a course: SEP 775 - Computational Natural Language Processing.\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"Given the context information and not prior knowledge, \"\n",
    "    \"answer the query.\\n\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"Answer: \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67649e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from documents\n",
    "documents = SimpleDirectoryReader(INPUT_DATA_PATH).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57a3f0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read QA pairs generated using ChatGPT with GPT-4\n",
    "sample_QA_pairs_df = pd.read_json(\"../data/question_answer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ff8bb96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>queries</th>\n",
       "      <th>responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the instructor's name for this course?</td>\n",
       "      <td>The instructor's name of the course is Hamidre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the email address of the instructor fo...</td>\n",
       "      <td>The email address of the instructor is mahyarh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When is this course held every week?</td>\n",
       "      <td>This course is held every Wednesday from 3:30p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the name of the TA for this course?</td>\n",
       "      <td>The TA's name for this course is Reza Namazi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is Word2vec?</td>\n",
       "      <td>Word2vec is a framework for learning word vect...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             queries  \\\n",
       "0     What is the instructor's name for this course?   \n",
       "1  What is the email address of the instructor fo...   \n",
       "2               When is this course held every week?   \n",
       "3        What is the name of the TA for this course?   \n",
       "4                                  What is Word2vec?   \n",
       "\n",
       "                                           responses  \n",
       "0  The instructor's name of the course is Hamidre...  \n",
       "1  The email address of the instructor is mahyarh...  \n",
       "2  This course is held every Wednesday from 3:30p...  \n",
       "3      The TA's name for this course is Reza Namazi.  \n",
       "4  Word2vec is a framework for learning word vect...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_QA_pairs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "258cfe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_QCR_data(query_engine, QA_pairs_df):\n",
    "    \"\"\"\n",
    "    Function to generate a question-context-response dataset to be evaluated, \n",
    "    the returned dataset also includes reference \"ground-truth\" response from the input.\n",
    "    \n",
    "    Parameters:\n",
    "    query_engine: LlamaIndex query engine object \n",
    "    QA_pairs_df: Dataframe that includes sample QA pairs \n",
    "    \n",
    "    Output:\n",
    "    QCR_ds: question-context-response dataset with features [question, answer, contexts, ground_truth]\n",
    "    \"\"\"\n",
    "    sample_questions = QA_pairs_df['queries'].values\n",
    "    ref_answers = QA_pairs_df['responses'].values\n",
    "    \n",
    "    print(\"Performing queries for %d sample questions...\"%len(sample_questions))\n",
    "    \n",
    "    contexts = []\n",
    "    answers = []\n",
    "    num_no_ans_Q = 0\n",
    "    for Q in tqdm(sample_questions):\n",
    "        response = query_engine.query(Q)\n",
    "        answer = str(response)\n",
    "\n",
    "        if (\"Empty Response\" in answer):\n",
    "            num_no_ans_Q += 1\n",
    "\n",
    "        contexts.append([x.node.get_content() for x in response.source_nodes])\n",
    "        answers.append(answer)\n",
    "    \n",
    "    print(\"In the %d sample questions, %d questions could not find relevant context.\"%(len(sample_questions),num_no_ans_Q))\n",
    "    # Take the question, context, response, and reference response of the first 40 queries for later evaluations\n",
    "    QCR_ds = Dataset.from_dict(\n",
    "        {\n",
    "            \"question\": sample_questions[:40],\n",
    "            \"answer\": answers[:40],\n",
    "            \"contexts\": contexts[:40],\n",
    "            \"ground_truth\": ref_answers[:40],\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return QCR_ds, num_no_ans_Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02f8327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_QCR_data(QCR_ds):\n",
    "    \"\"\"\n",
    "    Function to perform evaluation on question-context-response dataset\n",
    "    with answer_relevancy, faithfulness, answer_similarity, and context_relevancy metrics\n",
    "    \n",
    "    Outputs:\n",
    "    ans_eval_result: Evaluation results of answer_relevancy and faithfulness metrics\n",
    "    ans_sim_eval_result: Evaluation results of answer_similarity metric\n",
    "    contexts_eval_result: Evaluation results of context_relevancy metric\n",
    "    \"\"\"\n",
    "    print(\"Performing evaluation...\")\n",
    "    # Seldomly the evaluations could reach exception due to closed AsyncClient, \n",
    "    # but that DID NOT found to be affecting the evaluation results\n",
    "    # So we decided to not raise the exceptions during evaluations\n",
    "    ans_eval_result = evaluate(QCR_ds, [answer_relevancy, faithfulness],raise_exceptions=False)\n",
    "    ans_sim_eval_result = evaluate(QCR_ds.select_columns([\"question\",\"answer\",\"ground_truth\"]), \n",
    "                                   [answer_similarity],raise_exceptions=False)\n",
    "    contexts_eval_result = evaluate(QCR_ds.select_columns([\"question\",\"contexts\"]), [context_relevancy],raise_exceptions=False)\n",
    "    print(ans_eval_result)\n",
    "    print(contexts_eval_result)\n",
    "    print(ans_sim_eval_result)\n",
    "    \n",
    "    return ans_eval_result, ans_sim_eval_result, contexts_eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4da225dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_QCR_eval_result(filepath, QCR_ds, embed_model, chunk_top_k_settings, sys_prompt,\n",
    "                         ans_eval_result, ans_sim_eval_result, contexts_eval_result):\n",
    "    \"\"\"\n",
    "    Function to append evaluation results for each of the sample questions \n",
    "    with corresponding hyperparameter/embedding model choices into CSV file\n",
    "    \"\"\"\n",
    "    \n",
    "    eval_df = QCR_eval_result_df = pd.DataFrame({\n",
    "        \"question\": QCR_ds['question'],\n",
    "        \"answer\": QCR_ds['answer'],\n",
    "        \"contexts\": QCR_ds['contexts'],\n",
    "        \"embedding_model\": [embed_model]*40,\n",
    "        \"chunk_size\": [chunk_top_k_settings['chunk_size']]*40,\n",
    "        \"chunk_overlap\": [chunk_top_k_settings['chunk_overlap']]*40,\n",
    "        \"sim_top_k\": [chunk_top_k_settings['sim_top_k']]*40,\n",
    "        \"sys_prompt\": [sys_prompt]*40,\n",
    "        \"Answer Relevancy\": ans_eval_result.scores['answer_relevancy'],\n",
    "        \"Faithfulness\": ans_eval_result.scores['faithfulness'],\n",
    "        \"Answer Semantics Similarity\": ans_sim_eval_result.scores['answer_similarity'],\n",
    "        \"Context Relevancy\": contexts_eval_result.scores['context_relevancy']\n",
    "        })\n",
    "    \n",
    "    \n",
    "    if not os.path.exists(filepath):\n",
    "        eval_df.to_csv(filepath, mode='w')\n",
    "    \n",
    "    else:\n",
    "        curr_eval_df = pd.read_csv(filepath)\n",
    "        curr_eval_df.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "        concat_eval_df = pd.concat([curr_eval_df,eval_df])\n",
    "        concat_eval_df.reset_index(inplace=True,drop=True)\n",
    "        concat_eval_df.to_csv(filepath, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa471077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_hyper_param_eval_result(filepath, embedding_model, chunk_size, chunk_overlap, sim_top_k, long_or_short_sys_prompt, \n",
    "                                   answer_relevance, faithfulness, answer_similarity, context_relevance, \n",
    "                                   num_no_ans_Q):\n",
    "    \"\"\"\n",
    "    Function to append average evaluation result values over the sample questions \n",
    "    with corresponding hyperparameter/embedding model choices into CSV file\n",
    "    \"\"\"\n",
    "    if not os.path.exists(filepath):\n",
    "        with open(filepath,'a') as fd:\n",
    "            fd.write('embedding_model,chunk_size,chunk_overlap,sim_top_k,long_or_short_sys_prompt,Answer Relevance,'\\\n",
    "                     'Faithfulness,Answer Semantics Similarity,Context Relevance,Number of No Answer Question\\n')\n",
    "    \n",
    "    new_record_str = \"%s,%d,%d,%d,%s,%.3f,%.3f,%.3f,%.3f,%d\\n\"%(embedding_model,chunk_size,chunk_overlap,sim_top_k,\n",
    "                                                                long_or_short_sys_prompt,answer_relevance,faithfulness,\n",
    "                                                                answer_similarity,context_relevance,num_no_ans_Q)\n",
    "    print(new_record_str)\n",
    "    with open(filepath,'a') as fd:\n",
    "        fd.write(new_record_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fcd7cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_query_engine(vec_store_index, SIM_TOP_K, QA_PROMPT_TPL):\n",
    "    \"\"\"\n",
    "    Function to initialize LlamaIndex query engine, with specified similarity top k for retriever\n",
    "    and query prompt template\n",
    "    \"\"\"\n",
    "    print(\"Initializing Query Engine...\")\n",
    "    # configure retriever\n",
    "    retriever = VectorIndexRetriever(\n",
    "        index=vec_store_index,\n",
    "        similarity_top_k=SIM_TOP_K,\n",
    "    )\n",
    "\n",
    "    # configure postprocessor\n",
    "    postprocessor = SimilarityPostprocessor(\n",
    "        similarity_cutoff=0.30,\n",
    "    )\n",
    "\n",
    "    # configure response synthesizer\n",
    "    response_synthesizer = get_response_synthesizer()\n",
    "\n",
    "    # assemble query engine\n",
    "    query_engine=RetrieverQueryEngine(\n",
    "        retriever=retriever, \n",
    "        response_synthesizer=response_synthesizer,\n",
    "        node_postprocessors=[postprocessor],\n",
    "    )\n",
    "            \n",
    "    # Create a prompt template for the QA task   \n",
    "    qa_prompt_tmpl = PromptTemplate(QA_PROMPT_TPL)\n",
    "\n",
    "    # Update the prompt in the query engine\n",
    "    query_engine.update_prompts({\"response_synthesizer:text_qa_template\": qa_prompt_tmpl})\n",
    "    return query_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d3e4888",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating with Embedding Model: text-embedding-3-small\n",
      "Evaluating with (chunk size, chunk overlap, similarity-top-k): (512,20,2)\n",
      "Initializing index from documents...\n",
      "Initializing Query Engine...\n",
      "Performing queries for 90 sample questions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 90/90 [03:27<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the 90 sample questions, 0 questions could not find relevant context.\n",
      "Performing evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb59c0b3b1d04a74aa49d5d6de305302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d606a30a43cc49f28dca2c3db6d5371c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6421d4e183934f4ab1bdd9b40eda3355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer_relevancy': 0.9410, 'faithfulness': 0.8923}\n",
      "{'context_relevancy': 0.1160}\n",
      "{'answer_similarity': 0.9252}\n",
      "text-embedding-3-small,512,20,2,long,0.941,0.892,0.925,0.116,0\n",
      "\n",
      "Waiting for 1 minute...\n",
      "Initializing Query Engine...\n",
      "Performing queries for 90 sample questions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 90/90 [03:21<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the 90 sample questions, 0 questions could not find relevant context.\n",
      "Performing evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e555fc39c9744e7b86a9faf2856452d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6e7c144cf46470981f8e373999c9b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24969758422d43d4959be0d82cfcc9dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer_relevancy': 0.9113, 'faithfulness': 0.8769}\n",
      "{'context_relevancy': 0.1091}\n",
      "{'answer_similarity': 0.9248}\n",
      "text-embedding-3-small,512,20,2,short,0.911,0.877,0.925,0.109,0\n",
      "\n",
      "Waiting for 1 minute...\n",
      "Evaluating with (chunk size, chunk overlap, similarity-top-k): (256,10,4)\n",
      "Initializing index from documents...\n",
      "Initializing Query Engine...\n",
      "Performing queries for 90 sample questions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 90/90 [03:36<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the 90 sample questions, 0 questions could not find relevant context.\n",
      "Performing evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d512095db34d48569bbfe75e8bcbaf19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "695828cdbe874948b6bef083172b81aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc272a78ad44a4db15f4c09cf83f8b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer_relevancy': 0.9456, 'faithfulness': 0.8813}\n",
      "{'context_relevancy': 0.0755}\n",
      "{'answer_similarity': 0.9240}\n",
      "text-embedding-3-small,256,10,4,long,0.946,0.881,0.924,0.075,0\n",
      "\n",
      "Waiting for 1 minute...\n",
      "Initializing Query Engine...\n",
      "Performing queries for 90 sample questions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 90/90 [03:34<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the 90 sample questions, 0 questions could not find relevant context.\n",
      "Performing evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aac1f48a1164112990e503a29996ef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a913a72c6014b4f892766abefc50135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faf42fa994934124886289600863a236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer_relevancy': 0.9416, 'faithfulness': 0.8475}\n",
      "{'context_relevancy': 0.0642}\n",
      "{'answer_similarity': 0.9252}\n",
      "text-embedding-3-small,256,10,4,short,0.942,0.847,0.925,0.064,0\n",
      "\n",
      "Waiting for 1 minute...\n",
      "Evaluating with (chunk size, chunk overlap, similarity-top-k): (128,10,8)\n",
      "Initializing index from documents...\n",
      "Initializing Query Engine...\n",
      "Performing queries for 90 sample questions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 90/90 [04:27<00:00,  2.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the 90 sample questions, 0 questions could not find relevant context.\n",
      "Performing evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26dc984bc71849899b80cf865f3f3f6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e42a522a45d9422483db8ae265bc732d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5407be65a57e45cab532f576086e95e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer_relevancy': 0.9742, 'faithfulness': 0.8645}\n",
      "{'context_relevancy': 0.0772}\n",
      "{'answer_similarity': 0.9296}\n",
      "text-embedding-3-small,128,10,8,long,0.974,0.864,0.930,0.077,0\n",
      "\n",
      "Waiting for 1 minute...\n",
      "Initializing Query Engine...\n",
      "Performing queries for 90 sample questions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 90/90 [04:31<00:00,  3.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the 90 sample questions, 0 questions could not find relevant context.\n",
      "Performing evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52398a9ea114489ea124f36320228f16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcca77c7b0a9412a91b84fd7f741de67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e9a6a7af4149c5bc2e84a2c4fb81d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer_relevancy': 0.9745, 'faithfulness': 0.8733}\n",
      "{'context_relevancy': 0.0654}\n",
      "{'answer_similarity': 0.9253}\n",
      "text-embedding-3-small,128,10,8,short,0.974,0.873,0.925,0.065,0\n",
      "\n",
      "Waiting for 1 minute...\n",
      "Evaluating with Embedding Model: BAAI/bge-small-en-v1.5\n",
      "Evaluating with (chunk size, chunk overlap, similarity-top-k): (512,20,2)\n",
      "Initializing index from documents...\n",
      "Initializing Query Engine...\n",
      "Performing queries for 90 sample questions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 90/90 [02:48<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the 90 sample questions, 0 questions could not find relevant context.\n",
      "Performing evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60450b6f012f427e86b094a494c50061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecdbd87960b6494aa0da3c7a5302a1f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2296' coro=<AsyncClient.aclose() done, defined at C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_client.py\", line 2018, in aclose\n",
      "    await self._transport.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_transports\\default.py\", line 385, in aclose\n",
      "    await self._pool.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 313, in aclose\n",
      "    await self._close_connections(closing_connections)\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 305, in _close_connections\n",
      "    await connection.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection.py\", line 171, in aclose\n",
      "    await self._connection.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\http11.py\", line 265, in aclose\n",
      "    await self._network_stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 54, in aclose\n",
      "    await self._stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\anyio\\streams\\tls.py\", line 168, in aclose\n",
      "    await self.transport_stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1163, in aclose\n",
      "    self._transport.close()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\selector_events.py\", line 692, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\base_events.py\", line 719, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\base_events.py\", line 508, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2297' coro=<AsyncClient.aclose() done, defined at C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_client.py\", line 2018, in aclose\n",
      "    await self._transport.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_transports\\default.py\", line 385, in aclose\n",
      "    await self._pool.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 313, in aclose\n",
      "    await self._close_connections(closing_connections)\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 305, in _close_connections\n",
      "    await connection.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection.py\", line 171, in aclose\n",
      "    await self._connection.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\http11.py\", line 265, in aclose\n",
      "    await self._network_stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 54, in aclose\n",
      "    await self._stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\anyio\\streams\\tls.py\", line 168, in aclose\n",
      "    await self.transport_stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1163, in aclose\n",
      "    self._transport.close()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\selector_events.py\", line 692, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\base_events.py\", line 719, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\base_events.py\", line 508, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2300' coro=<AsyncClient.aclose() done, defined at C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_client.py\", line 2018, in aclose\n",
      "    await self._transport.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_transports\\default.py\", line 385, in aclose\n",
      "    await self._pool.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 313, in aclose\n",
      "    await self._close_connections(closing_connections)\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 305, in _close_connections\n",
      "    await connection.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection.py\", line 171, in aclose\n",
      "    await self._connection.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\http11.py\", line 265, in aclose\n",
      "    await self._network_stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 54, in aclose\n",
      "    await self._stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\anyio\\streams\\tls.py\", line 168, in aclose\n",
      "    await self.transport_stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1163, in aclose\n",
      "    self._transport.close()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\selector_events.py\", line 692, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\base_events.py\", line 719, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\base_events.py\", line 508, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2302' coro=<AsyncClient.aclose() done, defined at C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_client.py\", line 2018, in aclose\n",
      "    await self._transport.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_transports\\default.py\", line 385, in aclose\n",
      "    await self._pool.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 313, in aclose\n",
      "    await self._close_connections(closing_connections)\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 305, in _close_connections\n",
      "    await connection.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection.py\", line 171, in aclose\n",
      "    await self._connection.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\http11.py\", line 265, in aclose\n",
      "    await self._network_stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 54, in aclose\n",
      "    await self._stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\anyio\\streams\\tls.py\", line 168, in aclose\n",
      "    await self.transport_stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1163, in aclose\n",
      "    self._transport.close()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\selector_events.py\", line 692, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\base_events.py\", line 719, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\base_events.py\", line 508, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e2eadd6195f4502b148802bc2241f45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer_relevancy': 0.9442, 'faithfulness': 0.9006}\n",
      "{'context_relevancy': 0.0509}\n",
      "{'answer_similarity': 0.9160}\n",
      "BAAI/bge-small-en-v1.5,512,20,2,long,0.944,0.901,0.916,0.051,0\n",
      "\n",
      "Waiting for 1 minute...\n",
      "Initializing Query Engine...\n",
      "Performing queries for 90 sample questions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 90/90 [02:49<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the 90 sample questions, 0 questions could not find relevant context.\n",
      "Performing evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db80a1c5d599437fb1a7aeeccdf59c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ba4f656d1e44ee2a447ff6a453b772b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c34521a486544ac869c4f6d6176a057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer_relevancy': 0.9613, 'faithfulness': 0.8843}\n",
      "{'context_relevancy': 0.0509}\n",
      "{'answer_similarity': 0.9139}\n",
      "BAAI/bge-small-en-v1.5,512,20,2,short,0.961,0.884,0.914,0.051,0\n",
      "\n",
      "Waiting for 1 minute...\n",
      "Evaluating with (chunk size, chunk overlap, similarity-top-k): (256,10,4)\n",
      "Initializing index from documents...\n",
      "Initializing Query Engine...\n",
      "Performing queries for 90 sample questions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 90/90 [02:52<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the 90 sample questions, 0 questions could not find relevant context.\n",
      "Performing evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67b6e1744d9c412a8ec4e2ca2ee90559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3be447db1eb943948b0145bdc96555d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffa2315ec4724a9fa63bce4932efc8de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer_relevancy': 0.9670, 'faithfulness': 0.8514}\n",
      "{'context_relevancy': 0.0654}\n",
      "{'answer_similarity': 0.9220}\n",
      "BAAI/bge-small-en-v1.5,256,10,4,long,0.967,0.851,0.922,0.065,0\n",
      "\n",
      "Waiting for 1 minute...\n",
      "Initializing Query Engine...\n",
      "Performing queries for 90 sample questions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 90/90 [02:56<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the 90 sample questions, 0 questions could not find relevant context.\n",
      "Performing evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88372a5a193f485ca4cd15749998a77c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be49f2719916455ebf28d451ec6868f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15024cd3f0f14c098d3527a58fa234d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-3415' coro=<AsyncClient.aclose() done, defined at C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_client.py\", line 2018, in aclose\n",
      "    await self._transport.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_transports\\default.py\", line 385, in aclose\n",
      "    await self._pool.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 313, in aclose\n",
      "    await self._close_connections(closing_connections)\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 305, in _close_connections\n",
      "    await connection.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection.py\", line 171, in aclose\n",
      "    await self._connection.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\http11.py\", line 265, in aclose\n",
      "    await self._network_stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 54, in aclose\n",
      "    await self._stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\anyio\\streams\\tls.py\", line 168, in aclose\n",
      "    await self.transport_stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1163, in aclose\n",
      "    self._transport.close()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\selector_events.py\", line 692, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\base_events.py\", line 719, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\base_events.py\", line 508, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-3416' coro=<AsyncClient.aclose() done, defined at C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_client.py\", line 2018, in aclose\n",
      "    await self._transport.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_transports\\default.py\", line 385, in aclose\n",
      "    await self._pool.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 313, in aclose\n",
      "    await self._close_connections(closing_connections)\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 305, in _close_connections\n",
      "    await connection.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection.py\", line 171, in aclose\n",
      "    await self._connection.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\http11.py\", line 265, in aclose\n",
      "    await self._network_stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 54, in aclose\n",
      "    await self._stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\anyio\\streams\\tls.py\", line 168, in aclose\n",
      "    await self.transport_stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1163, in aclose\n",
      "    self._transport.close()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\selector_events.py\", line 692, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\base_events.py\", line 719, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\base_events.py\", line 508, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-3420' coro=<AsyncClient.aclose() done, defined at C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_client.py\", line 2018, in aclose\n",
      "    await self._transport.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_transports\\default.py\", line 385, in aclose\n",
      "    await self._pool.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 313, in aclose\n",
      "    await self._close_connections(closing_connections)\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 305, in _close_connections\n",
      "    await connection.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection.py\", line 171, in aclose\n",
      "    await self._connection.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\http11.py\", line 265, in aclose\n",
      "    await self._network_stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 54, in aclose\n",
      "    await self._stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\anyio\\streams\\tls.py\", line 168, in aclose\n",
      "    await self.transport_stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1163, in aclose\n",
      "    self._transport.close()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\selector_events.py\", line 692, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\base_events.py\", line 719, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\base_events.py\", line 508, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-3421' coro=<AsyncClient.aclose() done, defined at C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_client.py\", line 2018, in aclose\n",
      "    await self._transport.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_transports\\default.py\", line 385, in aclose\n",
      "    await self._pool.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 313, in aclose\n",
      "    await self._close_connections(closing_connections)\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 305, in _close_connections\n",
      "    await connection.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection.py\", line 171, in aclose\n",
      "    await self._connection.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\http11.py\", line 265, in aclose\n",
      "    await self._network_stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 54, in aclose\n",
      "    await self._stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\anyio\\streams\\tls.py\", line 168, in aclose\n",
      "    await self.transport_stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1163, in aclose\n",
      "    self._transport.close()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\selector_events.py\", line 692, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\base_events.py\", line 719, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\base_events.py\", line 508, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-3425' coro=<AsyncClient.aclose() done, defined at C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_client.py\", line 2018, in aclose\n",
      "    await self._transport.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_transports\\default.py\", line 385, in aclose\n",
      "    await self._pool.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 313, in aclose\n",
      "    await self._close_connections(closing_connections)\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 305, in _close_connections\n",
      "    await connection.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection.py\", line 171, in aclose\n",
      "    await self._connection.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\http11.py\", line 265, in aclose\n",
      "    await self._network_stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 54, in aclose\n",
      "    await self._stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\anyio\\streams\\tls.py\", line 168, in aclose\n",
      "    await self.transport_stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1163, in aclose\n",
      "    self._transport.close()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\selector_events.py\", line 692, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\base_events.py\", line 719, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\base_events.py\", line 508, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-3426' coro=<AsyncClient.aclose() done, defined at C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_client.py\", line 2018, in aclose\n",
      "    await self._transport.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_transports\\default.py\", line 385, in aclose\n",
      "    await self._pool.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 313, in aclose\n",
      "    await self._close_connections(closing_connections)\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 305, in _close_connections\n",
      "    await connection.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection.py\", line 171, in aclose\n",
      "    await self._connection.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\http11.py\", line 265, in aclose\n",
      "    await self._network_stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 54, in aclose\n",
      "    await self._stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\anyio\\streams\\tls.py\", line 168, in aclose\n",
      "    await self.transport_stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1163, in aclose\n",
      "    self._transport.close()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\selector_events.py\", line 692, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\base_events.py\", line 719, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\base_events.py\", line 508, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-3429' coro=<AsyncClient.aclose() done, defined at C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_client.py\", line 2018, in aclose\n",
      "    await self._transport.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_transports\\default.py\", line 385, in aclose\n",
      "    await self._pool.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 313, in aclose\n",
      "    await self._close_connections(closing_connections)\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 305, in _close_connections\n",
      "    await connection.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection.py\", line 171, in aclose\n",
      "    await self._connection.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\http11.py\", line 265, in aclose\n",
      "    await self._network_stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 54, in aclose\n",
      "    await self._stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\anyio\\streams\\tls.py\", line 168, in aclose\n",
      "    await self.transport_stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1163, in aclose\n",
      "    self._transport.close()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\selector_events.py\", line 692, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\base_events.py\", line 719, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\base_events.py\", line 508, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer_relevancy': 0.9713, 'faithfulness': 0.8408}\n",
      "{'context_relevancy': 0.0647}\n",
      "{'answer_similarity': 0.9270}\n",
      "BAAI/bge-small-en-v1.5,256,10,4,short,0.971,0.841,0.927,0.065,0\n",
      "\n",
      "Waiting for 1 minute...\n",
      "Evaluating with (chunk size, chunk overlap, similarity-top-k): (128,10,8)\n",
      "Initializing index from documents...\n",
      "Initializing Query Engine...\n",
      "Performing queries for 90 sample questions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 90/90 [03:14<00:00,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the 90 sample questions, 0 questions could not find relevant context.\n",
      "Performing evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6480d14f84aa4271a475afa45d62a712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ac2294bdc6f4c8fab26ec93fbadb193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd29668cb0ed47f88048c5c7fa1e56de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer_relevancy': 0.9503, 'faithfulness': 0.8164}\n",
      "{'context_relevancy': 0.0966}\n",
      "{'answer_similarity': 0.9252}\n",
      "BAAI/bge-small-en-v1.5,128,10,8,long,0.950,0.816,0.925,0.097,0\n",
      "\n",
      "Waiting for 1 minute...\n",
      "Initializing Query Engine...\n",
      "Performing queries for 90 sample questions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 90/90 [03:17<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the 90 sample questions, 0 questions could not find relevant context.\n",
      "Performing evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bba7bebaff64c55975060c8ed389957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf15285fca24967a309897d3d866ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa0bc0f17de0451592aac2bffb1a0356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer_relevancy': 0.9790, 'faithfulness': 0.8633}\n",
      "{'context_relevancy': 0.0953}\n",
      "{'answer_similarity': 0.9235}\n",
      "BAAI/bge-small-en-v1.5,128,10,8,short,0.979,0.863,0.923,0.095,0\n",
      "\n",
      "Waiting for 1 minute...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-718' coro=<AsyncClient.aclose() done, defined at C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_client.py\", line 2018, in aclose\n",
      "    await self._transport.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_transports\\default.py\", line 385, in aclose\n",
      "    await self._pool.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 313, in aclose\n",
      "    await self._close_connections(closing_connections)\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 305, in _close_connections\n",
      "    await connection.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection.py\", line 171, in aclose\n",
      "    await self._connection.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\http11.py\", line 265, in aclose\n",
      "    await self._network_stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 54, in aclose\n",
      "    await self._stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\anyio\\streams\\tls.py\", line 168, in aclose\n",
      "    await self.transport_stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1163, in aclose\n",
      "    self._transport.close()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\selector_events.py\", line 692, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\base_events.py\", line 719, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\base_events.py\", line 508, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-719' coro=<AsyncClient.aclose() done, defined at C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_client.py\", line 2018, in aclose\n",
      "    await self._transport.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_transports\\default.py\", line 385, in aclose\n",
      "    await self._pool.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 313, in aclose\n",
      "    await self._close_connections(closing_connections)\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 305, in _close_connections\n",
      "    await connection.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection.py\", line 171, in aclose\n",
      "    await self._connection.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\http11.py\", line 265, in aclose\n",
      "    await self._network_stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 54, in aclose\n",
      "    await self._stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\anyio\\streams\\tls.py\", line 168, in aclose\n",
      "    await self.transport_stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1163, in aclose\n",
      "    self._transport.close()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\selector_events.py\", line 692, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\base_events.py\", line 719, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\base_events.py\", line 508, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-723' coro=<AsyncClient.aclose() done, defined at C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_client.py\", line 2018, in aclose\n",
      "    await self._transport.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_transports\\default.py\", line 385, in aclose\n",
      "    await self._pool.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 313, in aclose\n",
      "    await self._close_connections(closing_connections)\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 305, in _close_connections\n",
      "    await connection.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection.py\", line 171, in aclose\n",
      "    await self._connection.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\http11.py\", line 265, in aclose\n",
      "    await self._network_stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 54, in aclose\n",
      "    await self._stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\anyio\\streams\\tls.py\", line 168, in aclose\n",
      "    await self.transport_stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1163, in aclose\n",
      "    self._transport.close()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\selector_events.py\", line 692, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\base_events.py\", line 719, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\base_events.py\", line 508, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-724' coro=<AsyncClient.aclose() done, defined at C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_client.py\", line 2018, in aclose\n",
      "    await self._transport.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_transports\\default.py\", line 385, in aclose\n",
      "    await self._pool.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 313, in aclose\n",
      "    await self._close_connections(closing_connections)\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 305, in _close_connections\n",
      "    await connection.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection.py\", line 171, in aclose\n",
      "    await self._connection.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\http11.py\", line 265, in aclose\n",
      "    await self._network_stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 54, in aclose\n",
      "    await self._stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\anyio\\streams\\tls.py\", line 168, in aclose\n",
      "    await self.transport_stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1163, in aclose\n",
      "    self._transport.close()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\selector_events.py\", line 692, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\base_events.py\", line 719, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\base_events.py\", line 508, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1438' coro=<AsyncClient.aclose() done, defined at C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_client.py\", line 2018, in aclose\n",
      "    await self._transport.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_transports\\default.py\", line 385, in aclose\n",
      "    await self._pool.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 313, in aclose\n",
      "    await self._close_connections(closing_connections)\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 305, in _close_connections\n",
      "    await connection.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection.py\", line 171, in aclose\n",
      "    await self._connection.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\http11.py\", line 265, in aclose\n",
      "    await self._network_stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 54, in aclose\n",
      "    await self._stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\anyio\\streams\\tls.py\", line 168, in aclose\n",
      "    await self.transport_stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1163, in aclose\n",
      "    self._transport.close()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\selector_events.py\", line 692, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\base_events.py\", line 719, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\base_events.py\", line 508, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1439' coro=<AsyncClient.aclose() done, defined at C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_client.py\", line 2018, in aclose\n",
      "    await self._transport.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_transports\\default.py\", line 385, in aclose\n",
      "    await self._pool.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 313, in aclose\n",
      "    await self._close_connections(closing_connections)\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 305, in _close_connections\n",
      "    await connection.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection.py\", line 171, in aclose\n",
      "    await self._connection.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\http11.py\", line 265, in aclose\n",
      "    await self._network_stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 54, in aclose\n",
      "    await self._stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\anyio\\streams\\tls.py\", line 168, in aclose\n",
      "    await self.transport_stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1163, in aclose\n",
      "    self._transport.close()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\selector_events.py\", line 692, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\base_events.py\", line 719, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\base_events.py\", line 508, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1443' coro=<AsyncClient.aclose() done, defined at C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_client.py\", line 2018, in aclose\n",
      "    await self._transport.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_transports\\default.py\", line 385, in aclose\n",
      "    await self._pool.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 313, in aclose\n",
      "    await self._close_connections(closing_connections)\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 305, in _close_connections\n",
      "    await connection.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection.py\", line 171, in aclose\n",
      "    await self._connection.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\http11.py\", line 265, in aclose\n",
      "    await self._network_stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 54, in aclose\n",
      "    await self._stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\anyio\\streams\\tls.py\", line 168, in aclose\n",
      "    await self.transport_stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1163, in aclose\n",
      "    self._transport.close()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\selector_events.py\", line 692, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\base_events.py\", line 719, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\base_events.py\", line 508, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1444' coro=<AsyncClient.aclose() done, defined at C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_client.py\", line 2018, in aclose\n",
      "    await self._transport.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_transports\\default.py\", line 385, in aclose\n",
      "    await self._pool.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 313, in aclose\n",
      "    await self._close_connections(closing_connections)\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 305, in _close_connections\n",
      "    await connection.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection.py\", line 171, in aclose\n",
      "    await self._connection.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\http11.py\", line 265, in aclose\n",
      "    await self._network_stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 54, in aclose\n",
      "    await self._stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\anyio\\streams\\tls.py\", line 168, in aclose\n",
      "    await self.transport_stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1163, in aclose\n",
      "    self._transport.close()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\selector_events.py\", line 692, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\base_events.py\", line 719, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\base_events.py\", line 508, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-3604' coro=<AsyncClient.aclose() done, defined at C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_client.py\", line 2018, in aclose\n",
      "    await self._transport.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpx\\_transports\\default.py\", line 385, in aclose\n",
      "    await self._pool.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 313, in aclose\n",
      "    await self._close_connections(closing_connections)\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 305, in _close_connections\n",
      "    await connection.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\connection.py\", line 171, in aclose\n",
      "    await self._connection.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_async\\http11.py\", line 265, in aclose\n",
      "    await self._network_stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 54, in aclose\n",
      "    await self._stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\anyio\\streams\\tls.py\", line 168, in aclose\n",
      "    await self.transport_stream.aclose()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1163, in aclose\n",
      "    self._transport.close()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\selector_events.py\", line 692, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\base_events.py\", line 719, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"C:\\Users\\jimta\\anaconda3\\envs\\NLP_env\\lib\\asyncio\\base_events.py\", line 508, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n"
     ]
    }
   ],
   "source": [
    "# Nested for loops for performing grid search on candidate hyperparameter values and embedding models\n",
    "for embed_model_id in cand_EMBED_MODEL:\n",
    "    print(\"Evaluating with Embedding Model: %s\"%embed_model_id)\n",
    "    # Set up embedding model\n",
    "    if 'bge-small' in embed_model_id:\n",
    "        Settings.embed_model = HuggingFaceEmbedding(model_name=embed_model_id, max_length=512)\n",
    "    else:\n",
    "        Settings.embed_model = OpenAIEmbedding(model=embed_model_id, max_length=1024)\n",
    "    for chunk_top_k_settings in cand_CHUNK_SIM_TOP_K:\n",
    "        print(\"Evaluating with (chunk size, chunk overlap, similarity-top-k): (%d,%d,%d)\"%(chunk_top_k_settings['chunk_size'],\n",
    "                                                                                           chunk_top_k_settings['chunk_overlap'],\n",
    "                                                                                           chunk_top_k_settings['sim_top_k']))\n",
    "        \n",
    "        # Set up chunk settings\n",
    "        Settings.chunk_size = chunk_top_k_settings['chunk_size']\n",
    "        Settings.chunk_overlap = chunk_top_k_settings['chunk_overlap']\n",
    "        print(\"Initializing index from documents...\")\n",
    "        # Initializing indices from documents\n",
    "        index = VectorStoreIndex.from_documents(documents)\n",
    "        for ith_sys_prompt in range(len(cand_SYS_PROMPT)):\n",
    "            # Set up LLM and tokenizer \n",
    "            llm = OpenAI(\n",
    "                temperature=0.3, \n",
    "                model=LLM_NAME, \n",
    "                system_prompt=cand_SYS_PROMPT[ith_sys_prompt],\n",
    "            )\n",
    "            Settings.llm = llm\n",
    "            Settings.tokenizer = tiktoken.encoding_for_model(TOKENIZER_NAME).encode\n",
    "            # Initialize query engine\n",
    "            query_engine = init_query_engine(index,chunk_top_k_settings['sim_top_k'],QA_PROMPT_TPL_str)\n",
    "            # perform queries and generate question-context-response data to be evaluated\n",
    "            QCR_ds, num_no_ans_Q = gen_QCR_data(query_engine, sample_QA_pairs_df)\n",
    "            # perform evaluation\n",
    "            ans_eval, ans_sim_eval, contexts_eval = eval_QCR_data(QCR_ds)\n",
    "            # Saving evaluation results\n",
    "            save_QCR_eval_result(QCR_EVAL_SAVE_PATH, QCR_ds, embed_model_id, chunk_top_k_settings, \n",
    "                                 cand_SYS_PROMPT[ith_sys_prompt], ans_eval, ans_sim_eval, contexts_eval)\n",
    "            \n",
    "            if ith_sys_prompt == 0:\n",
    "                append_hyper_param_eval_result(HYPER_PARAM_EVAL_SAVE_PATH,embed_model_id,chunk_top_k_settings['chunk_size'],\n",
    "                                               chunk_top_k_settings['chunk_overlap'],chunk_top_k_settings['sim_top_k'],\"long\",\n",
    "                                               ans_eval['answer_relevancy'],ans_eval['faithfulness'],\n",
    "                                               ans_sim_eval['answer_similarity'],contexts_eval['context_relevancy'],\n",
    "                                               num_no_ans_Q)\n",
    "            else:\n",
    "                append_hyper_param_eval_result(HYPER_PARAM_EVAL_SAVE_PATH,embed_model_id,chunk_top_k_settings['chunk_size'],\n",
    "                                               chunk_top_k_settings['chunk_overlap'],chunk_top_k_settings['sim_top_k'],\"short\",\n",
    "                                               ans_eval['answer_relevancy'],ans_eval['faithfulness'],\n",
    "                                               ans_sim_eval['answer_similarity'],contexts_eval['context_relevancy'],\n",
    "                                               num_no_ans_Q)\n",
    "            \n",
    "            # Let the program sleep for 2 minute to prevent exceeding OpenAI API rate limit\n",
    "            print(\"Waiting for 2 minute...\")\n",
    "            sleep(120)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0322f19a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding_model</th>\n",
       "      <th>chunk_size</th>\n",
       "      <th>chunk_overlap</th>\n",
       "      <th>sim_top_k</th>\n",
       "      <th>long_or_short_sys_prompt</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Semantics Similarity</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Number of No Answer Question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text-embedding-3-small</td>\n",
       "      <td>512</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>long</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>text-embedding-3-small</td>\n",
       "      <td>512</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>short</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>text-embedding-3-small</td>\n",
       "      <td>256</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>long</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>text-embedding-3-small</td>\n",
       "      <td>256</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>short</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>text-embedding-3-small</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>long</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>text-embedding-3-small</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>short</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BAAI/bge-small-en-v1.5</td>\n",
       "      <td>512</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>long</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BAAI/bge-small-en-v1.5</td>\n",
       "      <td>512</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>short</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BAAI/bge-small-en-v1.5</td>\n",
       "      <td>256</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>long</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BAAI/bge-small-en-v1.5</td>\n",
       "      <td>256</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>short</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BAAI/bge-small-en-v1.5</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>long</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BAAI/bge-small-en-v1.5</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>short</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           embedding_model  chunk_size  chunk_overlap  sim_top_k  \\\n",
       "0   text-embedding-3-small         512             20          2   \n",
       "1   text-embedding-3-small         512             20          2   \n",
       "2   text-embedding-3-small         256             10          4   \n",
       "3   text-embedding-3-small         256             10          4   \n",
       "4   text-embedding-3-small         128             10          8   \n",
       "5   text-embedding-3-small         128             10          8   \n",
       "6   BAAI/bge-small-en-v1.5         512             20          2   \n",
       "7   BAAI/bge-small-en-v1.5         512             20          2   \n",
       "8   BAAI/bge-small-en-v1.5         256             10          4   \n",
       "9   BAAI/bge-small-en-v1.5         256             10          4   \n",
       "10  BAAI/bge-small-en-v1.5         128             10          8   \n",
       "11  BAAI/bge-small-en-v1.5         128             10          8   \n",
       "\n",
       "   long_or_short_sys_prompt  Answer Relevance  Faithfulness  \\\n",
       "0                      long             0.941         0.892   \n",
       "1                     short             0.911         0.877   \n",
       "2                      long             0.946         0.881   \n",
       "3                     short             0.942         0.847   \n",
       "4                      long             0.974         0.864   \n",
       "5                     short             0.974         0.873   \n",
       "6                      long             0.944         0.901   \n",
       "7                     short             0.961         0.884   \n",
       "8                      long             0.967         0.851   \n",
       "9                     short             0.971         0.841   \n",
       "10                     long             0.950         0.816   \n",
       "11                    short             0.979         0.863   \n",
       "\n",
       "    Answer Semantics Similarity  Context Relevance  \\\n",
       "0                         0.925              0.116   \n",
       "1                         0.925              0.109   \n",
       "2                         0.924              0.075   \n",
       "3                         0.925              0.064   \n",
       "4                         0.930              0.077   \n",
       "5                         0.925              0.065   \n",
       "6                         0.916              0.051   \n",
       "7                         0.914              0.051   \n",
       "8                         0.922              0.065   \n",
       "9                         0.927              0.065   \n",
       "10                        0.925              0.097   \n",
       "11                        0.923              0.095   \n",
       "\n",
       "    Number of No Answer Question  \n",
       "0                              0  \n",
       "1                              0  \n",
       "2                              0  \n",
       "3                              0  \n",
       "4                              0  \n",
       "5                              0  \n",
       "6                              0  \n",
       "7                              0  \n",
       "8                              0  \n",
       "9                              0  \n",
       "10                             0  \n",
       "11                             0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(HYPER_PARAM_EVAL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6829cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
